name: UCSP Algorithm - Daily Incremental Update

# Actualización incremental diaria: trae últimos 7 días y mergea (~3 min)
# Corre martes-domingo. El lunes corre el full rebuild semanal.
on:
  # Ejecutar martes a domingo a las 1 PM UTC (8 AM Perú)
  schedule:
    - cron: '0 13 * * 2-7'

  # Permitir ejecución manual
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-commit:
    name: Incremental update - all sources (daily)
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      # 1. Checkout del código (incluyendo data existente para merge)
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      # 2. Setup Node.js 20
      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'scrapers/package-lock.json'

      # 3. Instalar dependencias
      - name: Install dependencies
        working-directory: ./scrapers
        run: npm ci

      # 4. Crear directorios de datos
      - name: Create data directories
        run: |
          mkdir -p data/trends data/tiktok data/meta data/hubspot
          mkdir -p public/data/trends public/data/tiktok public/data/meta public/data/hubspot

      # 5. Ejecutar scraper de Google Trends (Apify)
      - name: Run Google Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping Google Trends via Apify..."
          node google_trends_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 6. Ejecutar scraper de TikTok (Apify)
      - name: Run TikTok Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping TikTok Trends via Apify..."
          node tiktok_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 7. Ejecutar scraper de Meta/Facebook (Apify)
      - name: Run Meta/Facebook Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping Facebook Pages via Apify..."
          node meta_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 8. Ejecutar HubSpot CRM Connector (INCREMENTAL - 7 días, merge)
      - name: Run HubSpot CRM Connector (incremental)
        working-directory: ./scrapers
        run: |
          echo "HubSpot CRM incremental update (7 dias)..."
          node hubspot_api.js --client=ucsp --mode=incremental
        env:
          HUBSPOT_ACCESS_TOKEN: ${{ secrets.HUBSPOT_ACCESS_TOKEN }}
        continue-on-error: true

      # 9. Ejecutar ML Pipeline
      - name: Run ML Pipeline
        run: |
          echo "Ejecutando ML Pipeline..."
          node ml/pipeline/weekly_pipeline.js
        continue-on-error: true

      # 10. Verificar archivos generados
      - name: Check generated files
        run: |
          echo "Verificando archivos generados..."
          echo "=== HubSpot ===" && ls -lah data/hubspot/ || echo "No data"

      # 11. Commit y push de los datos
      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "UCSP Algorithm Bot"

          git add data/ public/data/

          if git diff --staged --quiet; then
            echo "No hay cambios en los datos"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            git commit -m "Daily incremental update - $TIMESTAMP"
            git push
            echo "Datos UCSP actualizados (incremental)"
          fi

      # 12. Notificación
      - name: Status notification
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "UCSP Algorithm daily update completado"
            echo "Proxima ejecucion: Manana 8 AM (Peru)"
          else
            echo "Algunos scrapers fallaron - revisa los logs"
          fi
