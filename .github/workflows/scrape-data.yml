name: UCSP Algorithm - Weekly Full Rebuild

# Full rebuild semanal: trae 730 días completos de HubSpot (~35 min)
# Garantiza consistencia total de datos históricos
on:
  # Ejecutar cada lunes a las 1 PM UTC (8 AM Perú)
  schedule:
    - cron: '0 13 * * 1'

  # Permitir ejecución manual desde GitHub Actions UI
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-commit:
    name: Full rebuild - all sources (weekly)
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      # 1. Checkout del código
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      # 2. Setup Node.js 20
      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'scrapers/package-lock.json'

      # 3. Instalar dependencias
      - name: Install dependencies
        working-directory: ./scrapers
        run: npm ci

      # 4. Crear directorios de datos
      - name: Create data directories
        run: |
          mkdir -p data/trends data/tiktok data/meta data/hubspot data/ga4
          mkdir -p public/data/trends public/data/tiktok public/data/meta public/data/hubspot public/data/ga4

      # 5. Ejecutar scraper de Google Trends (Apify)
      - name: Run Google Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping Google Trends via Apify..."
          node google_trends_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 6. Ejecutar scraper de TikTok (Apify)
      - name: Run TikTok Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping TikTok Trends via Apify..."
          node tiktok_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 7. Ejecutar scraper de Meta/Facebook (Apify)
      - name: Run Meta/Facebook Scraper
        working-directory: ./scrapers
        run: |
          echo "Scraping Facebook Pages via Apify..."
          node meta_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 8. Ejecutar HubSpot CRM Connector (FULL MODE - 730 días)
      - name: Run HubSpot CRM Connector (full rebuild)
        working-directory: ./scrapers
        run: |
          echo "HubSpot CRM full rebuild (730 dias)..."
          node hubspot_api.js --client=ucsp --mode=full
        env:
          HUBSPOT_ACCESS_TOKEN: ${{ secrets.HUBSPOT_ACCESS_TOKEN }}
        continue-on-error: true

      # 9. Ejecutar GA4 Data Connector (FULL MODE - 90 días)
      - name: Run GA4 Data Connector (full)
        working-directory: ./scrapers
        run: |
          echo "GA4 Analytics full fetch (90 dias)..."
          node ga4_api.js --client=ucsp --mode=full
        env:
          GA4_PROPERTY_ID: ${{ secrets.GA4_PROPERTY_ID }}
          GA4_CREDENTIALS_JSON: ${{ secrets.GA4_CREDENTIALS_JSON }}
        continue-on-error: true

      # 10. Ejecutar ML Pipeline
      - name: Run ML Pipeline
        run: |
          echo "Ejecutando ML Pipeline..."
          node ml/pipeline/weekly_pipeline.js
        continue-on-error: true

      # 11. Verificar archivos generados
      - name: Check generated files
        run: |
          echo "Verificando archivos generados..."
          echo "=== Google Trends ===" && ls -lah data/trends/ || echo "No data"
          echo "=== TikTok ===" && ls -lah data/tiktok/ || echo "No data"
          echo "=== Meta ===" && ls -lah data/meta/ || echo "No data"
          echo "=== HubSpot ===" && ls -lah data/hubspot/ || echo "No data"
          echo "=== GA4 ===" && ls -lah data/ga4/ || echo "No data"
          echo "=== ML ===" && ls -lah public/data/ml/ || echo "No ML data"

      # 12. Commit y push de los datos
      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "UCSP Algorithm Bot"

          git add data/ public/data/

          if git diff --staged --quiet; then
            echo "No hay cambios en los datos"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            git commit -m "Weekly full rebuild - $TIMESTAMP"
            git push
            echo "Datos UCSP actualizados (full rebuild)"
          fi

      # 13. Notificación
      - name: Status notification
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "UCSP Algorithm weekly rebuild completado"
            echo "Proximo full rebuild: Lunes 8 AM (Peru)"
          else
            echo "Algunos scrapers fallaron - revisa los logs"
          fi
